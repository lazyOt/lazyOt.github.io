<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>ARRoad：技术原理探究 | 芥 · 张</title><meta name="keywords" content="Put a dent in the universe..."><meta name="author" content="Zenc Fino"><meta name="copyright" content="Zenc Fino"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="ARRoad：技术原理探究位置追踪SLAM​    谈到位置追踪，不得不说SLAM(simultaneous localization and mapping)即时定位与地图映射， SLAM最早由科学家Smith、Self、Cheeseman于1988年提出，SLAM 问题可以描述为：将一个机器人放入未知环境中的未知位置，是否有办法让机器人逐步描绘出此环境完全的地图，所谓完全的地图（a consi">
<meta property="og:type" content="article">
<meta property="og:title" content="ARRoad：技术原理探究">
<meta property="og:url" content="http://example.com/2022/04/05/ARRoad%EF%BC%9A%E6%8A%80%E6%9C%AFy%E5%8E%9F%E7%90%86%E6%8E%A2%E7%A9%B6/index.html">
<meta property="og:site_name" content="芥 · 张">
<meta property="og:description" content="ARRoad：技术原理探究位置追踪SLAM​    谈到位置追踪，不得不说SLAM(simultaneous localization and mapping)即时定位与地图映射， SLAM最早由科学家Smith、Self、Cheeseman于1988年提出，SLAM 问题可以描述为：将一个机器人放入未知环境中的未知位置，是否有办法让机器人逐步描绘出此环境完全的地图，所谓完全的地图（a consi">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg">
<meta property="article:published_time" content="2022-04-05T02:28:03.000Z">
<meta property="article:modified_time" content="2022-04-05T03:04:57.531Z">
<meta property="article:author" content="Zenc Fino">
<meta property="article:tag" content="Put a dent in the universe...">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2022/04/05/ARRoad%EF%BC%9A%E6%8A%80%E6%9C%AFy%E5%8E%9F%E7%90%86%E6%8E%A2%E7%A9%B6/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap Titillium Web, 'PingFang SC', 'Hiragino Sans GB', 'Microsoft JhengHei', 'Microsoft YaHei', sans-serif" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-left"},
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'ARRoad：技术原理探究',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-04-05 11:04:57'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">20</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">芥 · 张</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">ARRoad：技术原理探究</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-04-05T02:28:03.000Z" title="发表于 2022-04-05 10:28:03">2022-04-05</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-04-05T03:04:57.531Z" title="更新于 2022-04-05 11:04:57">2022-04-05</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">7.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>22分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="ARRoad：技术原理探究"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="ARRoad：技术原理探究"><a href="#ARRoad：技术原理探究" class="headerlink" title="ARRoad：技术原理探究"></a>ARRoad：技术原理探究</h1><h2 id="位置追踪"><a href="#位置追踪" class="headerlink" title="位置追踪"></a>位置追踪</h2><h3 id="SLAM"><a href="#SLAM" class="headerlink" title="SLAM"></a>SLAM</h3><p>​    谈到位置追踪，不得不说SLAM(simultaneous localization and mapping)即时定位与地图映射， SLAM最早由科学家Smith、Self、Cheeseman于1988年提出，SLAM 问题可以描述为：将一个机器人放入未知环境中的未知位置，是否有办法让机器人逐步描绘出此环境完全的地图，所谓完全的地图（a consistent map）是指不受障碍行进到房间可进入的每个角落。</p>
<p>​    SLAM作为一种基础技术，从最早的军事用途（核潜艇海底定位就有了SLAM的雏形）到今天，已经逐步走入人们的视野。当前，在室外我们可以利用GPS、北斗等导航系统实现非常高精度的定位，甚至利用RTK的实时相位差分技术，能实现厘米的定位精度，基本上解决了室外的定位和定姿问题，但室内定位则发展则缓慢得多，为了实现室内的定位定姿，SLAM技术逐渐脱颖而出。</p>
<p>​    SLAM一般处理流程包括track和map两部分。所谓的track是用来估计相机的位姿，也叫前端，而map部分(后端)则是深度的构建，通过前面的跟踪模块估计得到相机的位姿，采用三角法(triangulation)计算相应特征点的深度，然后进行当前环境map的重建，重建出的map同时为前端提供更好的姿态估计，并可以用于例如闭环检测。</p>
<h3 id="解决SLAM中位姿的方法：VIO"><a href="#解决SLAM中位姿的方法：VIO" class="headerlink" title="解决SLAM中位姿的方法：VIO"></a>解决SLAM中位姿的方法：VIO</h3><p>​    定位与重建也是AR中必须解决的问题，不解决我在哪的问题，其他就无从谈起，目前，从技术角度来看，解决室内定位与定姿主要有视觉惯性测距系统（Visual Inertial Odometry，简称 VIO），VIO 意味着可以通过软件实时追踪用户的空间位置（用户在空间上的 6自由度姿势），6 自由度是指 xyz 方向上的三维运动（移动）加上俯仰／偏转／滚动（旋转）。VIO在每帧刷新之间重新计算用户的位置，速度为每秒 30 次及以上,这些计算是并行完成两次,通过视觉（摄像）系统将现实世界中的一个点与摄像机传感器上的一帧像素相匹配，从而追踪用户的姿势。惯性导航系统（用户的加速度计和陀螺仪跟踪统称为惯性测量单元，Inertial Measurement Unit，简称IMU）也可以追踪用户的姿势。在计算完上述过程之后，，卡尔曼滤波器（ Kalman Filter）结合两个系统的输出结果，决定哪一个系统提供的估测更接近用户的“真实”位置（地面实况）并通过软件更新当前位置。VIO 系统追踪用户的设备在六维空间里的移动，好比用户汽车里的里程表测量车的行驶距离一样。</p>
<p>​    VIO 带来的最大好处是 IMU 的读数大约为 1000次每秒并且是基于加速度的（用户的移动）。航迹推算法（Dead Reckoning）用于测量 IMU 读数之间的设备移动，但这种方法推算是一种估算，就像如果我让你向前走一步，然后猜测走了多远一样，此时会用航迹推算法来估计距离。但惯导系统中的误差会随时间累积，所以 IMU 帧率越长，惯导系统从视觉系统中复位后的时间越长，追踪位置距离真实位置偏差就越多。</p>
<h3 id="解决SLAM中位姿的方法：视觉测量"><a href="#解决SLAM中位姿的方法：视觉测量" class="headerlink" title="解决SLAM中位姿的方法：视觉测量"></a>解决SLAM中位姿的方法：视觉测量</h3><p> 视觉／光学测量使用的是摄像机来采集视觉信息，设备帧率通常为 30fps 并且依赖距离（不同的场景帧率也有所不同）。光学系统通常随着距离的增大误差也不断的增大（时间也会有轻度影响），所以用户运动得越远，误差就越大。</p>
<h3 id="VIO-视觉的比较和应用"><a href="#VIO-视觉的比较和应用" class="headerlink" title="VIO+视觉的比较和应用"></a>VIO+视觉的比较和应用</h3><p> 惯性导航系统与视觉测量系统各有各的优势和不足。并且视觉和惯性跟踪系统是基于完全不同的测量系统，他们之间并没有相互依赖。这意味着可以盖住摄像机或者只看到一个具有很少光学特征的场景（比如白墙），而惯性系统照样可以正常工作，或者设备在完全静止的条件下，视觉系统可以呈现出一个比惯性系统更加稳定的姿态。卡尔曼滤波器不断地选择最佳姿态，从而实现稳定跟踪。当前， VIO 系统已经存在很多年并在业界广泛认可，并且在应用市场已经有相当一部分应用。<br>  为了获得 精确的定们，需要从两个不同的地方获得场景视图，然后对当前位置进行立体计算。我们眼睛就是这样看到的 3D 效果，一些跟踪器也因此而依赖立体相机。如果你有两台相机就很容易计算，知道它们之间的距离，而且同时捕获帧，用一个相机你可以捕捉一次画面，然后移动到下一个位置进行第二次捕捉，然后进行视差计算。使用 IMU 航位推算你可以计算两次捕获位置之间的距离然后正常进行立体计算（事实上你可以多捕获几次使计算更加准确）。为了获得度量尺度，系统同时依赖 IMU 的精确航迹推算，从 IMU 提供的加速度和时间测量中，可以向后合并以计算速度并且再次向后合并以获取画面之间的实际距离，但是困难的是从 IMU 中除去误差以获得精确的加速度测量，在设备移动的几秒钟之内，一个微小的错误每秒运行一千次，就会造成 30% 或更大程度的误差积累。<br>  深度相机可以通过以下几种方式帮助 VIO 系统。在低特征场景中，深度相机对提高地面实况，度量标度以及边界追踪的精度方面有很大的帮助。但是它们非常耗能，因此只有在非常低的帧率以及帧间使用深度相机和 VIO 才是有意义的，它们在户外也不会正常运行，因为来自太阳光的红外散射会过滤掉深度相机中的红外线。移动设备深度相机的拍摄范围也比较有限，这意味它们只适合在手机上的短距离范围内使用(几米的范围)，另外深度相机在 BOM 成本方面也是非常昂贵的，因此 OEM 厂商避免在大容量手机上使用它们。<br>  立体 RGB 或鱼眼镜头都有助于看到更大范围的场景(因为立体 RGB 和鱼眼镜头具有潜在的光学特性。例如普通镜头可能只会看到白色的墙壁，但是一个鱼眼设备可以在画面中看到有图案的天花板和地毯 - Tango 和 Hololens 使用这种方法)。并且相对 VIO 而言，它们可以以更低的计算成本来获取深度信息，尽管 VIO 使用较低的 BOM 和功率也可以达到同样的精度。由于手机立体摄像头(即使是 HMD)之间的距离非常近，因此手机上深度计算的精度范围也被受到限制(相隔数厘米距离的手机相机在深度计算的误差上可以达到数米)。</p>
<h2 id="视觉校准"><a href="#视觉校准" class="headerlink" title="视觉校准"></a>视觉校准</h2><p><img src="https://img-blog.csdn.net/20180808222032507?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvbG9uMzAwMA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"></p>
<p>​    为了使软件能够精确地知道摄像机传感器上的像素是否能够与现实世界中的点相匹配，摄像机系统需要精确地校准。这儿有两种类型的校准：</p>
<h3 id="几何校准"><a href="#几何校准" class="headerlink" title="几何校准"></a>几何校准</h3><p>​    使用相机的针孔模型来校正镜头的视野和镜筒效果等。基本上由于镜头的形状所有的图像都会产生变形，大多数软件开发人员可以在没有 OEM（Original Equipment Manufacturer,原始设备制造商) 输入的情况下使用棋盘格和基本公开的相机规格进行几何校正。</p>
<h3 id="光度校准"><a href="#光度校准" class="headerlink" title="光度校准"></a>光度校准</h3><p>​    这里涉及到很多东西，通常要求 OEM 厂商参与。因为光度校准涉及到图像传感器本身的细节特征以及内部透镜所有的涂层等，光度校准一般用于处理色彩和强度的映射。例如，正在拍摄遥远星星的望远镜连接的摄像机需要知道传感器上一个像素光强度的轻微变化是否确实是星星还是仅仅来源于传感器或透镜中的像差。光度校准对于 AR 跟踪器的好处是提高了传感器上的像素和真实世界中的点的匹配度，因此视觉跟踪具有更强的鲁棒性以及更少的错误。</p>
<h2 id="惯性校准"><a href="#惯性校准" class="headerlink" title="惯性校准"></a>惯性校准</h2><p>​    当我们在思考 IMU 时，记住 IMU 是用来测量加速度而不是距离或速度的，这点很重要，距离是时间的二次方，IMU 读取错误造成的计算结果会随着时间的推移快速积累，校准和建模的目标就是确保距离测量足够精确。理想情况下，在使用IMU时可以使摄像机是有足够长的时间来弥补由于用户覆盖镜头或者场景中发生其他事情所造成数帧跟踪的丢失。使用 IMU 测量距离被称为航迹推算，这是一种估测，但是通过对 IMU 的行为进行建模，找出产生错误的所有方式，然后通过编写过滤器来减少这些错误，可以使这个估测更加精确。想象一下如果你被要求向前走一步，然后猜测你走了几米这样的场景，仅凭一步然后去估算会有很大的误差，但是如果你重复走上千步，那么对你每步的估测与你行走距离的估测最终会变得非常准确，这基本上就是 IMU 校准和建模的原理。<br>  在 IMU 中会有很多错误来源。假设一个机器臂通常用于以完全相同的方式重复地移动设备，来自其 IMU 的输出会一直被捕获和过滤，直到 IMU 的输出能够和机器臂的实况移动十分精确地匹配，这就是一种校准与建模的过程，Google 和微软甚至将它们的设备发送到太空微重力环境中以便消除额外的错误。要想获得真正的精确度会比它听起来要更难，对于设备产商而言，他们必须在它所有组合的全部设备中解决这些问题。</p>
<h2 id="三维重建"><a href="#三维重建" class="headerlink" title="三维重建"></a>三维重建</h2><h3 id="为什么要用？"><a href="#为什么要用？" class="headerlink" title="为什么要用？"></a>为什么要用？</h3><p> 3D 重建(3D Reconstruction，在 Hololens 术语中叫空间映射或在 Tango 术语中叫深度感知)。3D 重建系统能够找出场景中真实物体的形状和结构，并且允许虚拟事物之间相互碰撞以及隐藏在真实世界的后面，如上图所示，要将虚拟物体隐藏在真实物体之后，那么前提就必须要对真实物体进行识别与重建。3D重建目前来看还有很多难点需要克服，当前很多AR Demos 都没有支持 3D 重建，因此 AR 中的虚拟内容看起来仅仅是在镜头中现实物体的前面移动而已。3D 重建通过从场景中捕获密集的点云(使用深度相机或者RGB相机)，然后将其转换为网格，并将隐形网格传递给3D引擎(连同真实世界的坐标),之后将真实世界网格精准地放置在相机所捕获的场景上，重建后虚拟事物就可以与现实世界互动。</p>
<h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><p> （1） 图像获取：在进行图像处理之前，先要用摄像机获取三维物体的二维图像。光照条件、相机的几何特性等对后续的图像处理会造成很大的影响。<br>  （2）摄像机标定：通过摄像机标定来建立有效的成像模型，求解出摄像机的内外参数，这样就可以结合图像的匹配结果得到空间中的三维点坐标，从而达到进行三维重建的目的。<br>  （3）特征提取：特征主要包括特征点、特征线和区域。大多数情况下都是以特征点为匹配基元，特征点以何种形式提取与用何种匹配策略紧密联系。因此在进行特征点的提取时需要先确定用哪种匹配方法。特征点提取算法可以总结为：基于方向导数的方法，基于图像亮度对比关系的方法，基于数学形态学的方法三种。<br>  （4）立体匹配：立体匹配是指根据所提取的特征来建立图像对之间的一种对应关系，也就是将同一物理空间点在两幅不同图像中的成像点进行一一对应起来。在进行匹配时要注意场景中一些因素的干扰，比如光照条件、噪声干扰、景物几何形状畸变、表面物理特性以及摄像机机特性等诸多变化因素。<br>  （5）三维重建：有了比较精确的匹配结果，结合摄像机标定的内外参数，就可以恢复出三维场景信息。由于三维重建精度受匹配精度，摄像机的内外参数误差等因素的影响，只有重建前各个环节的精度高，误差小，这样才能设计出一个比较精确的立体视觉系统。</p>
<h2 id="ARCore"><a href="#ARCore" class="headerlink" title="ARCore"></a>ARCore</h2><h3 id="ARCore做了什么？"><a href="#ARCore做了什么？" class="headerlink" title="ARCore做了什么？"></a>ARCore做了什么？</h3><p>​    从本质上讲，ARCore 在做三件事：运动追踪、环境理解、光估计。</p>
<p>​    ARCore 的运动跟踪技术使用手机摄像头标识兴趣点（称为特征点），并跟踪这些点随着时间变化的移动。 将这些点的移动与手机惯性传感器的读数组合，ARCore 可以在手机移动时确定它的位置和屏幕方向。除了标识关键点外，ARCore 还会检测平坦的表面（例如桌子或地面），并估测周围区域的平均光照强度。 </p>
<p>​    这些功能共同让 ARCore 可以构建自己对周围世界的理解。借助 ARCore 对现实世界的理解，我们能够以一种与现实世界无缝整合的方式添加物体、注释或其他信息。 可以将一只打盹的小猫放在咖啡桌的一角，或者利用艺术家的生平信息为一幅画添加注释。 运动跟踪意味着可以移动和从任意角度查看这些物体，即使当我们转身离开房间，当回来后，小猫或注释还会在其最初添加的地方。</p>
<h3 id="运动追踪"><a href="#运动追踪" class="headerlink" title="运动追踪"></a>运动追踪</h3><p><img src="https://img-blog.csdn.net/20180809211443179?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvbG9uMzAwMA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"></p>
<p> 在2D和3D空间中跟踪用户的运动并最终定位它们的位置是任何AR应用程序的基础，当我们的移动设备在现实世界中移动时，ARCore 会通过一个名为并行测距与映射（Concurrent Odometry and Mapping ，COM）的过程来理解手机相对于周围世界的位置。 ARCore 会检测捕获的摄像头图像中的视觉差异特征（称为特征点），并使用这些点来计算其位置变化。 这些视觉信息将与设备 IMU 的惯性测量结果结合，一起用于估测摄像头随着时间推移而相对于周围世界的姿态（位置和方向）。如上图所示，在图中，我们可以看到用户的位置是如何与真实沙发上识别的特征点相关联的，以前为了成功跟踪运动（位置），我们需要预先训练我们的特征点，有了ARCore，它个实时的自动为我们做这些，这种跟踪技术是非常新的，当然，它也有它的不足，后面我们会谈到。</p>
<p>​    在开发中，通过将渲染 3D 内容的虚拟摄像头的姿态与 ARCore 提供的设备摄像头的姿态对齐，开发者能够从正确的透视角度渲染虚拟内容，渲染的虚拟图像可以叠加到从设备摄像头获取的图像上，让虚拟内容看起来就像现实世界的一部分一样。</p>
<h3 id="环境理解"><a href="#环境理解" class="headerlink" title="环境理解"></a>环境理解</h3><p><img src="https://img-blog.csdn.net/20180809213257795?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvbG9uMzAwMA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"></p>
<p>​    ARCore 会通过检测特征点和平面来不断改进它对现实世界环境的理解。ARCore 可以查找看起来位于常见水平或垂直表面（例如桌子或墙）上的成簇特征点，并让这些表面可以用作应用程序的平面， ARCore 也可以确定每个平面的边界，并将该信息提供给应用，使用此信息将可以将虚拟物体置于平坦的表面上。由于 ARCore 使用特征点来检测平面，因此可能无法正确检测像白墙一样没有纹理的平坦表面，这一点是由算法的底层设计决定的，除非附加其它算法，否则这个问题不可解。在后续的文章中我们将详细讨论环境理解的细节，看一下下面这张图：</p>
<p><img src="https://img-blog.csdn.net/20180809213842960?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvbG9uMzAwMA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"></p>
<p>​    在上面的图像中我们看到的是一个通过网格识别的真实世界表面，这个平面是由白点标识，在场景中，我们可以看到用户是如何将各种虚拟物体放置在表面上的。环境理解和啮合对于创建AR视觉表现来说是必不可少的。</p>
<h3 id="光估计"><a href="#光估计" class="headerlink" title="光估计"></a>光估计</h3><p><img src="https://img-blog.csdn.net/20180809214159758?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvbG9uMzAwMA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"></p>
<p>​    ARCore 可以检测其环境光线的相关信息，并提供给定摄像头图像的平均光强度和色彩校正，利用这些光照信息，我们可以使用与周围环境相同的光照来照亮您的虚拟物体，提升虚拟物体的真实感。在上图中，处于强光中的猫与处于阴影中的猫的颜色保持了与真实场景中光照的一致。利用ARCore，还可以用来估计光源的位置和光照方向，这样，可以让虚拟物体产生与真实光照一样的阴影效果，进一步提升虚拟物体的真实性。</p>
<h3 id="其他概念"><a href="#其他概念" class="headerlink" title="其他概念"></a>其他概念</h3><h4 id="用户交互"><a href="#用户交互" class="headerlink" title="用户交互"></a>用户交互</h4><p>  ARCore 利用命中测试来获取对应于手机屏幕的 (x,y) 坐标（通过点按或应用支持的任何其他交互提供），并将一条射线投影到摄像头的视野中，返回这条射线贯穿的任何平面或特征点以及交叉位置在现实世界空间中的姿态。 这让用户可以选择环境中的物体或者与它们互动。</p>
<h4 id="定向点"><a href="#定向点" class="headerlink" title="定向点"></a>定向点</h4><p>  借助定向点，可以将虚拟物体置于倾斜的表面上。当执行会返回特征点的命中测试时，ARCore 将查看附近的特征点并使用这些特征点估算表面在给定特征点处的角度，然后，ARCore 会返回一个将该角度考虑在内的姿态。由于 ARCore 使用成簇特征点来检测表面的角度，因此可能无法正确检测像白墙一样没有纹理的表面。</p>
<h4 id="锚点和可跟踪对象"><a href="#锚点和可跟踪对象" class="headerlink" title="锚点和可跟踪对象"></a>锚点和可跟踪对象</h4><p>  姿态会随着 ARCore 改进它对自身位置和环境的理解而变化，当我们要放置一个虚拟物体时，需要定义一个锚点来确保 ARCore 可以跟踪物体随时间推移的位置，很多时候，需要基于命中测试返回的姿态创建一个锚点，以此来绑定虚拟物体与真实环境的位置关系。姿态会发生变化，这就意味着 ARCore 可能会更新平面和特征点等环境物体随时间推移的位置。 平面和特征点是一种特殊类型的物体，称为可跟踪对象，顾名思义，ARCore 可以随着时间推移跟踪这些物体。 我们可以将虚拟物体锚定到特定的可跟踪对象，确保虚拟物体与可跟踪对象之间的关系即使在设备移动时也能保持稳定。 这意味着，如果将一个虚拟的 Android 小雕像放在书桌上，即使 ARCore 稍后调整了与书桌关联的平面的姿态，Android 小雕像仍会看起来位于桌子上。注：为了减少 CPU 开销，请尽可能重用锚点并在不再需要时分离锚点。<br>  锚点描述了在现实世界中一个固定的位置和方向。为了保持在物理空间的固定位置，这个位置的数值描述将会随着ARCore对空间的理解的改进而更新。使用getPose()获取这个Anchor的当前数值位置，这个位置每次update()被调用的时候都可能改变，但不会自发地改变。</p>
<h4 id="增强图像"><a href="#增强图像" class="headerlink" title="增强图像"></a>增强图像</h4><p>  使用增强图像可以构建能够响应特定 2D 图像（如产品包装或电影海报）的 AR 应用， 用户可以在将手机的摄像头对准特定图像时触发 AR 体验，例如，他们可以将手机的摄像头对准电影海报，使人物弹出，然后引发一个场景。可离线编译图像以创建图像数据库，也可以从设备实时添加单独的图像。 注册后，ARCore 将检测这些图像、图像边界，然后返回相应的姿态。</p>
<h4 id="共享"><a href="#共享" class="headerlink" title="共享"></a>共享</h4><p>  借助 ARCore 的 Cloud Anchors API，您可以创建适用于 Android 和 iOS 设备的协作性或多人游戏应用。使用云锚点，一台设备可以将锚点和附近的特征点发送到云端进行托管。 可以将这些锚点与同一环境中 Android 或 iOS 设备上的其他用户共享。 这使应用可以渲染连接到这些锚点的相同 3D 对象，从而让用户能够同步拥有相同的 AR 体验。由于国内网络环境问题，我们可能无法使用Cloud Anchors。</p>
<h4 id="帧（com-google-ar-core-Frame）"><a href="#帧（com-google-ar-core-Frame）" class="headerlink" title="帧（com.google.ar.core.Frame）"></a>帧（com.google.ar.core.Frame）</h4><p>  Frame最直观的理解是照相机获取的一帧图像，背景渲染的画面就来自摄像头获取图像帧。在ARCore中，Frame还包含更丰富的内容，还提供了某一个时刻AR的状态。这些状态包括：当前帧中环境的光线，如在绘制内容的时候根据光线控制物体绘制的颜色，使得更真实；当前Frame中检测到的特征点云和它的Pose用来绘制点云；当前Frame中包含的Anchor和检测到的Plane集合用于绘制内容和平面；手机设备当前的Pose、帧获取的时间戳、AR跟踪状态和摄像头的视图矩阵等。</p>
<h4 id="特征点云（com-google-ar-core-PointCloud）"><a href="#特征点云（com-google-ar-core-PointCloud）" class="headerlink" title="特征点云（com.google.ar.core.PointCloud）"></a>特征点云（com.google.ar.core.PointCloud）</h4><p>  ARCore在检测平面的时候，显示的一个个小白点，就是特征点云。特征点云包含了被观察到的3D点和信心值的集合，还有它被ARCore检测时的时间戳。</p>
<h4 id="二维平面（com-google-ar-core-Plane）"><a href="#二维平面（com-google-ar-core-Plane）" class="headerlink" title="二维平面（com.google.ar.core.Plane）"></a>二维平面（com.google.ar.core.Plane）</h4><p>  ARCore中所有的内容，都要依托于平面类进行渲染。如演示中的Android机器人，只有在检测到网格的地方才能放置。ARCore中平面可分为水平朝上、朝下、垂直和非水平平面类型，Plane描述了对一个真实世界二维平面的认知，如平面的中心点、平面的x和z轴方向长度，组成平面多边形的顶点。检测到的平面还分为三种状态，分别是正在跟踪，可恢复跟踪和永不恢复跟踪。如果是没有正在跟踪的平面，包含的平面信息可能不准确。两个或者多个平面还会被被自动合并成一个父平面。如果这种情况发生，可以通过子平面找到它的父平面。</p>
<h4 id="交集（com-google-ar-core-HitResult-PlaneHitResult-PointCloudHitResult）"><a href="#交集（com-google-ar-core-HitResult-PlaneHitResult-PointCloudHitResult）" class="headerlink" title="交集（com.google.ar.core.HitResult/PlaneHitResult/PointCloudHitResult）"></a>交集（com.google.ar.core.HitResult/PlaneHitResult/PointCloudHitResult）</h4><p>  点击平面的时候，从设备点击处朝手机面向方向发出一条射线，和被检测平面的是否有交集。抽象的概括，HitResult就是射线和真实世界几何体的交集。我们可以中获取当前设备到有交集几何体的距离，交集的Pose，如果是平面交集就是PlaneHitResult，如果是点云就是PoinCludHitResult，PlaneHitResult中可以判断交集点是否在被检测的集合范围内，是否在平面的正面。</p>
<h4 id="空间位置（com-google-ar-core-Pose）"><a href="#空间位置（com-google-ar-core-Pose）" class="headerlink" title="空间位置（com.google.ar.core.Pose）"></a>空间位置（com.google.ar.core.Pose）</h4><p>  Pose表示从一个坐标系到另一个坐标系的转换。在所有的ARCore APIs中，Pose总是描述从物体的局部坐标系到世界坐标系的变换，也就是说，来自ARCore API的Pose可以被认为等同于OpenGL的模型矩阵或DirectX的世界矩阵。随着ARCore对环境的了解不断变化，它将调整坐标系模式以便与真实世界保持一致。 这时，Camera和锚点的位置（坐标）可能会发生明显的变化，以便它们所代表的物体处理恰当的位置。因此，每一帧图像都应被认为是在一个完全独立的世界坐标空间中。锚点和Camera的坐标不应该在渲染帧之外的地方使用，如果需考虑到某个位置超出单个渲染框架的范围，则应该创建一个锚点或者应该使用相对于附近现有锚点的位置。</p>
<h4 id="空间光线（com-google-ar-core-LightEstimate）"><a href="#空间光线（com-google-ar-core-LightEstimate）" class="headerlink" title="空间光线（com.google.ar.core.LightEstimate）"></a>空间光线（com.google.ar.core.LightEstimate）</h4><p>  LightEstimate给我们提供了一个接口来查询当前帧的光环境。我们可以获取当前相机视图的像素强度，一个范围在（0.0，1.0）的值，0代表黑色，1代表白色。使用该光线属性绘制内容，可以使虚拟物体更真实。</p>
<h4 id="会话（com-google-ar-core-Session）"><a href="#会话（com-google-ar-core-Session）" class="headerlink" title="会话（com.google.ar.core.Session）"></a>会话（com.google.ar.core.Session）</h4><p>  Session是ARCore中重要的功能是管理AR系统的状态，处理Session生命周期，是ARCore API的主要入口。在开始使用ARCore API的时候，通过设置的Config来检查当前设备是否支持ARCore。在Activity中对应的生命周期方法中需要处理Session的生命周期，这样AR系统会根据需要开始和暂停相机帧的采集，初始化和释放相关的资源。<br>  Session是ARCore API的一个类com.google.ar.core.Session。它管理了AR系统的状态，有自己的生命周期，开始和停止访问摄像头图像帧的获取。Session管理AR系统的全部状态，包含跟踪的Anchor信息、通过session.add(Pose)和session.removeAnchor(anchors)保存和删除。session.getAllPlanes()返回被检测到的平面、当前投影矩阵等。当ARCore App退至后台，Activity调用onPause()方法时，也需要通过session.pause()暂停Session，来停止摄像机的图像获取，在App呈现在前台的时候，onResume()方法中调用session.resume(Config)可以重新启用Session，获取摄像机图像等。可以通过调用session.update()方法来获取最新的相机帧，更新设备的位置，更新被跟踪的Anchor信息，更新被检查的平面。在AR系统在每一帧画面的渲染过程中，我们从Session中获取当前相机反馈的Frame，根据需要保存、获取和删除Anchor，获取系统检测到的所有Plane，设置纵横缩放比，获取投影矩阵（渲染3d效果）等用于渲染相关工作。</p>
<h4 id="配置（com-google-ar-core-Config）"><a href="#配置（com-google-ar-core-Config）" class="headerlink" title="配置（com.google.ar.core.Config）"></a>配置（com.google.ar.core.Config）</h4><p>  在当前市面上，并不是所有的Android设备都支持ARCore。那么这时候我们就要用到Config，它保存了用于配置Session相关设置。我们可以针对是否开启平面检测和光线感知，获取帧时没有新图片是否阻塞等几个选项创建Config。默认Config开启平面检测和光线感知，获取帧时没有新图片阻塞。 在使用ARCore之前，使用创建的Config，检查当前设备是否支持ARCore，是一个比较好的做法。配置文件主要包括：光线评估子系统的行为Config.LightingMode，包含开启或者禁止光线评估；平面检测子系统的行为Config.PlaneFindingMode，包含开启和禁止平面检测；update()的行为Config.UpdateMode。在大多数设备中，摄像头被配置每秒捕捉30帧。当调用update()从摄像机获取帧的时，没有新的相机图片包含两种行为：立即返回和阻塞等待。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Zenc Fino</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2022/04/05/ARRoad%EF%BC%9A%E6%8A%80%E6%9C%AFy%E5%8E%9F%E7%90%86%E6%8E%A2%E7%A9%B6/">http://example.com/2022/04/05/ARRoad%EF%BC%9A%E6%8A%80%E6%9C%AFy%E5%8E%9F%E7%90%86%E6%8E%A2%E7%A9%B6/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">芥 · 张</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2022/04/02/vue2%EF%BC%9AProp/"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">vue2：Prop</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Zenc Fino</div><div class="author-info__description">Put a dent in the universe...</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">20</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/lazyOt"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/lazyOt" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:zencfino@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#ARRoad%EF%BC%9A%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E6%8E%A2%E7%A9%B6"><span class="toc-number">1.</span> <span class="toc-text">ARRoad：技术原理探究</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%8D%E7%BD%AE%E8%BF%BD%E8%B8%AA"><span class="toc-number">1.1.</span> <span class="toc-text">位置追踪</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#SLAM"><span class="toc-number">1.1.1.</span> <span class="toc-text">SLAM</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3SLAM%E4%B8%AD%E4%BD%8D%E5%A7%BF%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%9AVIO"><span class="toc-number">1.1.2.</span> <span class="toc-text">解决SLAM中位姿的方法：VIO</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3SLAM%E4%B8%AD%E4%BD%8D%E5%A7%BF%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%9A%E8%A7%86%E8%A7%89%E6%B5%8B%E9%87%8F"><span class="toc-number">1.1.3.</span> <span class="toc-text">解决SLAM中位姿的方法：视觉测量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#VIO-%E8%A7%86%E8%A7%89%E7%9A%84%E6%AF%94%E8%BE%83%E5%92%8C%E5%BA%94%E7%94%A8"><span class="toc-number">1.1.4.</span> <span class="toc-text">VIO+视觉的比较和应用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%86%E8%A7%89%E6%A0%A1%E5%87%86"><span class="toc-number">1.2.</span> <span class="toc-text">视觉校准</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%A0%E4%BD%95%E6%A0%A1%E5%87%86"><span class="toc-number">1.2.1.</span> <span class="toc-text">几何校准</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%89%E5%BA%A6%E6%A0%A1%E5%87%86"><span class="toc-number">1.2.2.</span> <span class="toc-text">光度校准</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%83%AF%E6%80%A7%E6%A0%A1%E5%87%86"><span class="toc-number">1.3.</span> <span class="toc-text">惯性校准</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA"><span class="toc-number">1.4.</span> <span class="toc-text">三维重建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%94%A8%EF%BC%9F"><span class="toc-number">1.4.1.</span> <span class="toc-text">为什么要用？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A5%E9%AA%A4"><span class="toc-number">1.4.2.</span> <span class="toc-text">步骤</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ARCore"><span class="toc-number">1.5.</span> <span class="toc-text">ARCore</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ARCore%E5%81%9A%E4%BA%86%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">1.5.1.</span> <span class="toc-text">ARCore做了什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%90%E5%8A%A8%E8%BF%BD%E8%B8%AA"><span class="toc-number">1.5.2.</span> <span class="toc-text">运动追踪</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8E%AF%E5%A2%83%E7%90%86%E8%A7%A3"><span class="toc-number">1.5.3.</span> <span class="toc-text">环境理解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%89%E4%BC%B0%E8%AE%A1"><span class="toc-number">1.5.4.</span> <span class="toc-text">光估计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E6%A6%82%E5%BF%B5"><span class="toc-number">1.5.5.</span> <span class="toc-text">其他概念</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%94%A8%E6%88%B7%E4%BA%A4%E4%BA%92"><span class="toc-number">1.5.5.1.</span> <span class="toc-text">用户交互</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E5%90%91%E7%82%B9"><span class="toc-number">1.5.5.2.</span> <span class="toc-text">定向点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%94%9A%E7%82%B9%E5%92%8C%E5%8F%AF%E8%B7%9F%E8%B8%AA%E5%AF%B9%E8%B1%A1"><span class="toc-number">1.5.5.3.</span> <span class="toc-text">锚点和可跟踪对象</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A2%9E%E5%BC%BA%E5%9B%BE%E5%83%8F"><span class="toc-number">1.5.5.4.</span> <span class="toc-text">增强图像</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B1%E4%BA%AB"><span class="toc-number">1.5.5.5.</span> <span class="toc-text">共享</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B8%A7%EF%BC%88com-google-ar-core-Frame%EF%BC%89"><span class="toc-number">1.5.5.6.</span> <span class="toc-text">帧（com.google.ar.core.Frame）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E7%82%B9%E4%BA%91%EF%BC%88com-google-ar-core-PointCloud%EF%BC%89"><span class="toc-number">1.5.5.7.</span> <span class="toc-text">特征点云（com.google.ar.core.PointCloud）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%8C%E7%BB%B4%E5%B9%B3%E9%9D%A2%EF%BC%88com-google-ar-core-Plane%EF%BC%89"><span class="toc-number">1.5.5.8.</span> <span class="toc-text">二维平面（com.google.ar.core.Plane）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%A4%E9%9B%86%EF%BC%88com-google-ar-core-HitResult-PlaneHitResult-PointCloudHitResult%EF%BC%89"><span class="toc-number">1.5.5.9.</span> <span class="toc-text">交集（com.google.ar.core.HitResult&#x2F;PlaneHitResult&#x2F;PointCloudHitResult）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A9%BA%E9%97%B4%E4%BD%8D%E7%BD%AE%EF%BC%88com-google-ar-core-Pose%EF%BC%89"><span class="toc-number">1.5.5.10.</span> <span class="toc-text">空间位置（com.google.ar.core.Pose）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A9%BA%E9%97%B4%E5%85%89%E7%BA%BF%EF%BC%88com-google-ar-core-LightEstimate%EF%BC%89"><span class="toc-number">1.5.5.11.</span> <span class="toc-text">空间光线（com.google.ar.core.LightEstimate）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%9A%E8%AF%9D%EF%BC%88com-google-ar-core-Session%EF%BC%89"><span class="toc-number">1.5.5.12.</span> <span class="toc-text">会话（com.google.ar.core.Session）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%EF%BC%88com-google-ar-core-Config%EF%BC%89"><span class="toc-number">1.5.5.13.</span> <span class="toc-text">配置（com.google.ar.core.Config）</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/04/05/ARRoad%EF%BC%9A%E6%8A%80%E6%9C%AFy%E5%8E%9F%E7%90%86%E6%8E%A2%E7%A9%B6/" title="ARRoad：技术原理探究"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="ARRoad：技术原理探究"/></a><div class="content"><a class="title" href="/2022/04/05/ARRoad%EF%BC%9A%E6%8A%80%E6%9C%AFy%E5%8E%9F%E7%90%86%E6%8E%A2%E7%A9%B6/" title="ARRoad：技术原理探究">ARRoad：技术原理探究</a><time datetime="2022-04-05T02:28:03.000Z" title="发表于 2022-04-05 10:28:03">2022-04-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/04/02/vue2%EF%BC%9AProp/" title="vue2：Prop"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="vue2：Prop"/></a><div class="content"><a class="title" href="/2022/04/02/vue2%EF%BC%9AProp/" title="vue2：Prop">vue2：Prop</a><time datetime="2022-04-02T03:56:54.000Z" title="发表于 2022-04-02 11:56:54">2022-04-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/04/02/js%E4%B8%AD%E4%BD%BF%E7%94%A8map%E9%81%8D%E5%8E%86/" title="JavaScript：map"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="JavaScript：map"/></a><div class="content"><a class="title" href="/2022/04/02/js%E4%B8%AD%E4%BD%BF%E7%94%A8map%E9%81%8D%E5%8E%86/" title="JavaScript：map">JavaScript：map</a><time datetime="2022-04-02T02:42:05.000Z" title="发表于 2022-04-02 10:42:05">2022-04-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/04/02/vue2%EF%BC%9Aref/" title="vue2：ref"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="vue2：ref"/></a><div class="content"><a class="title" href="/2022/04/02/vue2%EF%BC%9Aref/" title="vue2：ref">vue2：ref</a><time datetime="2022-04-02T02:41:44.000Z" title="发表于 2022-04-02 10:41:44">2022-04-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/04/01/vue2%E4%B8%AD%E4%BD%BF%E7%94%A8axios/" title="vue2中使用axios"><img src="/img/axios.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="vue2中使用axios"/></a><div class="content"><a class="title" href="/2022/04/01/vue2%E4%B8%AD%E4%BD%BF%E7%94%A8axios/" title="vue2中使用axios">vue2中使用axios</a><time datetime="2022-04-01T11:13:09.000Z" title="发表于 2022-04-01 19:13:09">2022-04-01</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2021 - 2022 By Zenc Fino</div><div class="footer_custom_text">Towering genius disdains a beaten path. It seeks regions hitherto unexplored.</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: '',
      appKey: '',
      placeholder: 'Please leave your footprints',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'en',
      recordIP: false,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: false,
      path: window.location.pathname,
      requiredFields: ["nick,mail"],
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>